{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "import config as cf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load US_Reopen Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape =  (44186, 8)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 44186 entries, 0 to 44185\n",
      "Data columns (total 8 columns):\n",
      "id               44186 non-null int64\n",
      "created_at       44186 non-null object\n",
      "original_text    44186 non-null object\n",
      "clean_text       44186 non-null object\n",
      "sentiment        44186 non-null object\n",
      "lang             44186 non-null object\n",
      "screen_name      44186 non-null object\n",
      "location         44186 non-null object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(cf.US_REOPEN_DATA)\n",
    "df = df.dropna()\n",
    "print(\"Shape = \", df.shape)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Retweet Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11410, 8)\n",
      "Shape =  (11410, 8)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11410 entries, 8 to 44185\n",
      "Data columns (total 8 columns):\n",
      "id               11410 non-null int64\n",
      "created_at       11410 non-null object\n",
      "original_text    11410 non-null object\n",
      "clean_text       11410 non-null object\n",
      "sentiment        11410 non-null object\n",
      "lang             11410 non-null object\n",
      "screen_name      11410 non-null object\n",
      "location         11410 non-null object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 802.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df[df.apply(lambda x: not x[\"original_text\"].startswith(\"RT\"), axis=1)]\n",
    "print(df.shape)\n",
    "print(\"Shape = \", df.shape)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess and Extract Words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11410 entries, 8 to 44185\n",
      "Data columns (total 9 columns):\n",
      "id               11410 non-null int64\n",
      "created_at       11410 non-null object\n",
      "original_text    11410 non-null object\n",
      "clean_text       11410 non-null object\n",
      "sentiment        11410 non-null object\n",
      "lang             11410 non-null object\n",
      "screen_name      11410 non-null object\n",
      "location         11410 non-null object\n",
      "key_words        11410 non-null object\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 891.4+ KB\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import gazetteers\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re, calendar\n",
    "\n",
    "stopwords  = [w.lower() for w in list(stopwords.words('english'))]\n",
    "gazetteers = [x.lower() for x in gazetteers.words()]\n",
    "skips = [\"covid\", \"corona\", \"new\", \"novel\", \"open\", \"amp\", \"repu\"]\n",
    "calendars = [m.lower() for m in list(calendar.month_name) + list(calendar.day_name)]\n",
    "\n",
    "def get_key_words(tweet):\n",
    "    tweet = tweet.lower() #lowercase\n",
    "    tweet = re.sub(cf.RX_MENTION, '', tweet) #mention\n",
    "    tweet = re.sub(cf.RX_HASHTAG, '', tweet) #hashtag\n",
    "    tweet = re.sub(cf.RX_URL, '', tweet) #url\n",
    "    tweet = re.sub(cf.RX_EMAIL, '', tweet) #email\n",
    "    words = TweetTokenizer().tokenize(tweet)\n",
    "    words = [re.sub(cf.RX_ONLY_AB, '', w) for w in words] #only alphabet\n",
    "    words = [w for w in words if len(w) > 3] #word length\n",
    "    words = [w for w in words if w.lower() not in stopwords]\n",
    "    words = [w for w in words if w.lower() not in gazetteers]\n",
    "    words = [w for w in words if w.lower() not in calendars]\n",
    "    for ws in skips:\n",
    "        words = [w for w in words if ws.lower() not in w.lower()]\n",
    "    words = [WordNetLemmatizer().lemmatize(w) for w in words]\n",
    "    return words\n",
    "\n",
    "df[\"key_words\"] = df[\"original_text\"].apply(get_key_words)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-gram, N = [1, 2, 3] and T = 15:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-grams(word,count,perentage):\n",
      "[('state', 1275, '1.65E-2'), ('business', 1179, '1.53E-2'), ('plan', 587, '7.60E-3'), ('economy', 548, '7.09E-3'), ('people', 485, '6.28E-3'), ('today', 477, '6.17E-3'), ('back', 454, '5.88E-3'), ('case', 444, '5.75E-3'), ('testing', 431, '5.58E-3'), ('country', 419, '5.42E-3'), ('need', 416, '5.38E-3'), ('phase', 401, '5.19E-3'), ('county', 378, '4.89E-3'), ('restaurant', 351, '4.54E-3'), ('week', 340, '4.40E-3')]\n",
      "\n",
      "2-grams(word,count,perentage):\n",
      "[('testing site', 141, '2.14E-3'), ('social distancing', 107, '1.62E-3'), ('white house', 88, '1.34E-3'), ('state begin', 62, '9.41E-4'), ('small business', 61, '9.26E-4'), ('look like', 59, '8.95E-4'), ('public health', 56, '8.50E-4'), ('stay home', 48, '7.28E-4'), ('back work', 45, '6.83E-4'), ('wear mask', 43, '6.52E-4'), ('hair salon', 41, '6.22E-4'), ('next week', 39, '5.92E-4'), ('task force', 34, '5.16E-4'), ('business begin', 34, '5.16E-4'), ('contact tracing', 33, '5.01E-4')]\n",
      "\n",
      "3-grams(word,count,perentage):\n",
      "[('drivethru testing site', 20, '3.66E-4'), ('moderate discussion business', 20, '3.66E-4'), ('discussion business leader', 20, '3.66E-4'), ('keep calling transparency', 20, '3.66E-4'), ('calling transparency investigation', 20, '3.66E-4'), ('transparency investigation fort', 20, '3.66E-4'), ('stock fluctuated economic', 18, '3.29E-4'), ('fluctuated economic plan', 18, '3.29E-4'), ('economic plan mixed', 18, '3.29E-4'), ('plan mixed earnings', 18, '3.29E-4'), ('mixed earnings company', 18, '3.29E-4'), ('training class course', 18, '3.29E-4'), ('class course offer', 18, '3.29E-4'), ('course offer full', 18, '3.29E-4'), ('offer full service', 17, '3.11E-4')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "from collections import Counter\n",
    "from decimal import Decimal\n",
    "\n",
    "N = 3 #N-grams\n",
    "T = 15 #Max top words\n",
    "\n",
    "def n_grams(kw, n):\n",
    "    output = []\n",
    "    for i in range(len(kw)-n+1):\n",
    "        output.append(kw[i:i+n])\n",
    "    return output\n",
    "\n",
    "for n in range(1, N+1):\n",
    "    key_words = df[\"key_words\"].tolist()\n",
    "    key_words = [[' '.join(x) for x in n_grams(kw, n)] for kw in key_words]\n",
    "    key_words = [[each_word] for each_list in key_words for each_word in each_list]\n",
    "    count = dict(Counter(map(tuple, key_words)))\n",
    "    count = sorted(count.items(), key=lambda x: x[1], reverse=True)\n",
    "    count = [(c[0][0],c[1]) for c in count]\n",
    "    sumc = sum([c[1] for c in count])\n",
    "    def get_sci_val(x):\n",
    "        x = round(x/sumc, 6)\n",
    "        x = \"{:.2E}\".format(Decimal(x))\n",
    "        return x\n",
    "    count = [(c[0],c[1],get_sci_val(c[1])) for c in count]\n",
    "    print(\"{}-grams(word,count,perentage):\\n{}\\n\".format(n,count[:T]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
